{"version":3,"names":["vocab","exports","title","words","word","translation","example"],"sources":["23_intelligence_artificielle.js"],"sourcesContent":["export const vocab = {\n  title: \"Intelligence Artificielle et Analyse de Données\",\n  words: [\n    // Concepts fondamentaux de l'IA et du ML (50 mots)\n\n    {\n      word: \"validation data\",\n      translation: \"données de validation\",\n      example:\n        \"Hyperparameters were optimized using performance on the validation data, separate from the training set.\",\n    },\n    {\n      word: \"test data\",\n      translation: \"données de test\",\n      example:\n        \"The final evaluation used previously unseen test data to assess real-world performance.\",\n    },\n\n    {\n      word: \"hyperparameter optimization\",\n      translation: \"optimisation des hyperparamètres\",\n      example:\n        \"Bayesian hyperparameter optimization efficiently explores the parameter space by leveraging information from previous evaluations.\",\n    },\n\n    {\n      word: \"loss function\",\n      translation: \"fonction de perte\",\n      example:\n        \"The loss function quantifies the difference between predicted outputs and ground truth values.\",\n    },\n\n    {\n      word: \"discriminative model\",\n      translation: \"modèle discriminatif\",\n      example:\n        \"Discriminative models focus on decision boundaries between classes rather than modeling the full data distribution.\",\n    },\n    {\n      word: \"classification\",\n      translation: \"classification\",\n      example:\n        \"The classification algorithm assigns input examples to discrete categories based on their features.\",\n    },\n\n    {\n      word: \"clustering\",\n      translation: \"regroupement\",\n      example:\n        \"Clustering algorithms identify natural groupings in data based on similarity measures.\",\n    },\n    {\n      word: \"dimensionality reduction\",\n      translation: \"réduction de dimensionnalité\",\n      example:\n        \"Dimensionality reduction techniques compress high-dimensional data while preserving important structures.\",\n    },\n\n    {\n      word: \"random forest\",\n      translation: \"forêt aléatoire\",\n      example:\n        \"Random forests combine multiple decision trees to reduce overfitting and improve generalization.\",\n    },\n    {\n      word: \"gradient boosting\",\n      translation: \"amplification de gradient\",\n      example:\n        \"Gradient boosting sequentially builds models that correct errors made by previous iterations.\",\n    },\n    {\n      word: \"support vector machine\",\n      translation: \"machine à vecteurs de support\",\n      example:\n        \"Support vector machines find optimal hyperplanes that maximize the margin between different classes.\",\n    },\n    {\n      word: \"k-nearest neighbors\",\n      translation: \"k plus proches voisins\",\n      example:\n        \"The k-nearest neighbors algorithm classifies points based on majority votes from their closest neighbors.\",\n    },\n    {\n      word: \"convolutional neural network\",\n      translation: \"réseau neuronal convolutif\",\n      example:\n        \"Convolutional neural networks excel at visual recognition tasks through specialized layer architectures.\",\n    },\n    {\n      word: \"recurrent neural network\",\n      translation: \"réseau neuronal récurrent\",\n      example:\n        \"Recurrent neural networks process sequential data by maintaining internal state information.\",\n    },\n    {\n      word: \"transformer\",\n      translation: \"transformeur\",\n      example:\n        \"Transformer architectures revolutionized language processing through attention mechanisms and parallel computation.\",\n    },\n    {\n      word: \"generative adversarial network\",\n      translation: \"réseau antagoniste génératif\",\n      example:\n        \"Generative adversarial networks consist of competing networks that simultaneously improve generation quality.\",\n    },\n    {\n      word: \"reinforcement learning agent\",\n      translation: \"agent d'apprentissage par renforcement\",\n      example:\n        \"The reinforcement learning agent learned optimal strategies through repeated interactions with its environment.\",\n    },\n\n    {\n      word: \"speech recognition\",\n      translation: \"reconnaissance vocale\",\n      example:\n        \"The speech recognition system converts spoken language into text with contextual understanding.\",\n    },\n\n    // Techniques avancées et modèles (50 mots)\n    {\n      word: \"deep neural network\",\n      translation: \"réseau neuronal profond\",\n      example:\n        \"Deep neural networks with multiple layers can learn increasingly abstract representations of input data.\",\n    },\n\n    {\n      word: \"multilayer perceptron\",\n      translation: \"perceptron multicouche\",\n      example:\n        \"The multilayer perceptron contains input, hidden, and output layers fully connected between adjacent levels.\",\n    },\n    {\n      word: \"activation function\",\n      translation: \"fonction d'activation\",\n      example:\n        \"Non-linear activation functions enable neural networks to model complex relationships in data.\",\n    },\n    {\n      word: \"rectified linear unit\",\n      translation: \"unité linéaire rectifiée\",\n      example:\n        \"ReLU activation functions accelerate training by addressing vanishing gradient problems in deep networks.\",\n    },\n    {\n      word: \"softmax function\",\n      translation: \"fonction softmax\",\n      example:\n        \"The softmax function converts raw model outputs into probability distributions across classes.\",\n    },\n    {\n      word: \"batch normalization\",\n      translation: \"normalisation par lots\",\n      example:\n        \"Batch normalization stabilizes and accelerates neural network training by normalizing layer inputs.\",\n    },\n    {\n      word: \"dropout\",\n      translation: \"abandon\",\n      example:\n        \"Dropout prevents co-adaptation of neurons by randomly deactivating units during training.\",\n    },\n    {\n      word: \"early stopping\",\n      translation: \"arrêt précoce\",\n      example:\n        \"Early stopping prevents overfitting by terminating training when validation performance begins to deteriorate.\",\n    },\n    {\n      word: \"parameter tuning\",\n      translation: \"ajustement des paramètres\",\n      example:\n        \"Systematic parameter tuning identified optimal configuration for the production model.\",\n    },\n    {\n      word: \"batch size\",\n      translation: \"taille du lot\",\n      example:\n        \"Larger batch sizes enable more stable gradient estimates but require more memory during training.\",\n    },\n    {\n      word: \"learning rate\",\n      translation: \"taux d'apprentissage\",\n      example:\n        \"Adaptive learning rate schedules adjust optimization step sizes throughout training for better convergence.\",\n    },\n    {\n      word: \"weight initialization\",\n      translation: \"initialisation des poids\",\n      example:\n        \"Proper weight initialization prevents signal vanishing or explosion in deep networks.\",\n    },\n\n    {\n      word: \"self-attention\",\n      translation: \"auto-attention\",\n      example:\n        \"Self-attention allows models to consider relationships between all positions in a sequence simultaneously.\",\n    },\n    {\n      word: \"multi-head attention\",\n      translation: \"attention multi-têtes\",\n      example:\n        \"Multi-head attention projects inputs into multiple subspaces to capture different relationship types.\",\n    },\n    {\n      word: \"encoder-decoder architecture\",\n      translation: \"architecture encodeur-décodeur\",\n      example:\n        \"Encoder-decoder architectures transform input sequences into intermediate representations before generating outputs.\",\n    },\n    {\n      word: \"long short-term memory\",\n      translation: \"mémoire à long et à court terme\",\n      example:\n        \"LSTM units maintain information over extended sequences through specialized gating mechanisms.\",\n    },\n    {\n      word: \"gated recurrent unit\",\n      translation: \"unité récurrente à portes\",\n      example:\n        \"GRUs simplify LSTM architecture while maintaining ability to capture long-range dependencies.\",\n    },\n    {\n      word: \"sequence-to-sequence model\",\n      translation: \"modèle séquence-à-séquence\",\n      example:\n        \"Sequence-to-sequence models transform input sequences into output sequences of potentially different lengths.\",\n    },\n    {\n      word: \"autoencoder\",\n      translation: \"auto-encodeur\",\n      example:\n        \"Autoencoders learn efficient data representations by reconstructing inputs through compressed encodings.\",\n    },\n    {\n      word: \"variational autoencoder\",\n      translation: \"auto-encodeur variationnel\",\n      example:\n        \"Variational autoencoders learn probabilistic latent representations enabling controlled generation.\",\n    },\n\n    {\n      word: \"fine-tuning\",\n      translation: \"ajustement fin\",\n      example:\n        \"Fine-tuning adapts pre-trained models to specific domains or tasks with smaller, specialized datasets.\",\n    },\n\n    {\n      word: \"meta-learning\",\n      translation: \"méta-apprentissage\",\n      example:\n        \"Meta-learning algorithms learn how to learn, developing strategies that generalize across different tasks.\",\n    },\n    {\n      word: \"multitask learning\",\n      translation: \"apprentissage multitâche\",\n      example:\n        \"Multitask learning simultaneously trains models on related tasks to improve performance through shared representations.\",\n    },\n\n    {\n      word: \"domain adaptation\",\n      translation: \"adaptation de domaine\",\n      example:\n        \"Domain adaptation techniques bridge distribution gaps between training and deployment environments.\",\n    },\n\n    {\n      word: \"curriculum learning\",\n      translation: \"apprentissage par curriculum\",\n      example:\n        \"Curriculum learning presents training examples in increasing complexity to facilitate more efficient learning.\",\n    },\n\n    {\n      word: \"multimodal learning\",\n      translation: \"apprentissage multimodal\",\n      example:\n        \"Multimodal learning integrates information from different data types like text, images, and audio.\",\n    },\n    {\n      word: \"graph neural network\",\n      translation: \"réseau neuronal de graphe\",\n      example:\n        \"Graph neural networks process data with irregular structure by operating on node and edge representations.\",\n    },\n    {\n      word: \"knowledge distillation\",\n      translation: \"distillation de connaissances\",\n      example:\n        \"Knowledge distillation transfers capabilities from larger models to smaller, more efficient ones.\",\n    },\n\n    {\n      word: \"pruning\",\n      translation: \"élagage\",\n      example:\n        \"Network pruning removes redundant parameters to create smaller, more efficient models without significant performance loss.\",\n    },\n    {\n      word: \"model deployment\",\n      translation: \"déploiement de modèle\",\n      example:\n        \"Model deployment integrates AI systems into production environments with monitoring and maintenance capabilities.\",\n    },\n    {\n      word: \"model serving\",\n      translation: \"service de modèle\",\n      example:\n        \"Efficient model serving infrastructure handles prediction requests at scale with low latency requirements.\",\n    },\n    {\n      word: \"model versioning\",\n      translation: \"versionnage de modèle\",\n      example:\n        \"Model versioning systems track changes throughout the development lifecycle for reproducibility and rollback capabilities.\",\n    },\n    {\n      word: \"model monitoring\",\n      translation: \"surveillance de modèle\",\n      example:\n        \"Continuous model monitoring detects performance degradation and data drift in production environments.\",\n    },\n\n    // Analyse de données et techniques statistiques (50 mots)\n\n    {\n      word: \"exploratory data analysis\",\n      translation: \"analyse exploratoire des données\",\n      example:\n        \"Exploratory data analysis examines distributions and relationships before formal modeling begins.\",\n    },\n\n    {\n      word: \"p-value\",\n      translation: \"valeur p\",\n      example:\n        \"The p-value quantifies evidence against the null hypothesis in hypothesis testing.\",\n    },\n\n    {\n      word: \"correlation\",\n      translation: \"corrélation\",\n      example:\n        \"Correlation measures strength and direction of relationships between variables without implying causation.\",\n    },\n\n    {\n      word: \"linear regression\",\n      translation: \"régression linéaire\",\n      example:\n        \"Linear regression models relationships between variables using straight-line functions.\",\n    },\n    {\n      word: \"logistic regression\",\n      translation: \"régression logistique\",\n      example:\n        \"Logistic regression predicts categorical outcomes through probability estimation.\",\n    },\n\n    {\n      word: \"principal component analysis\",\n      translation: \"analyse en composantes principales\",\n      example:\n        \"Principal component analysis reduces dimensionality while preserving maximum variance.\",\n    },\n\n    {\n      word: \"seasonality\",\n      translation: \"saisonnalité\",\n      example:\n        \"The analysis revealed strong seasonality with consistent patterns repeating annually.\",\n    },\n\n    {\n      word: \"association rule learning\",\n      translation: \"apprentissage des règles d'association\",\n      example:\n        \"Association rule learning identifies co-occurring elements within transactional datasets.\",\n    },\n\n    {\n      word: \"pivot table\",\n      translation: \"tableau croisé dynamique\",\n      example:\n        \"Pivot tables aggregate and summarize data across multiple dimensions for comparative analysis.\",\n    },\n    {\n      word: \"heatmap\",\n      translation: \"carte thermique\",\n      example:\n        \"The correlation heatmap visually represents relationship strengths between multiple variables.\",\n    },\n    {\n      word: \"scatter plot\",\n      translation: \"nuage de points\",\n      example:\n        \"Scatter plots reveal relationships between two continuous variables including potential non-linearities.\",\n    },\n    {\n      word: \"histogram\",\n      translation: \"histogramme\",\n      example:\n        \"Histograms display frequency distributions of continuous variables across defined intervals.\",\n    },\n    {\n      word: \"box plot\",\n      translation: \"boîte à moustaches\",\n      example:\n        \"Box plots summarize distributions through quartiles while highlighting potential outliers.\",\n    },\n\n    {\n      word: \"data preprocessing\",\n      translation: \"prétraitement des données\",\n      example:\n        \"Data preprocessing transforms raw information into formats suitable for modeling and analysis.\",\n    },\n\n    {\n      word: \"feature selection\",\n      translation: \"sélection des caractéristiques\",\n      example:\n        \"Feature selection identifies the most informative variables while removing redundant or irrelevant ones.\",\n    },\n\n    {\n      word: \"ETL process\",\n      translation: \"processus ETL\",\n      example:\n        \"ETL processes extract data from sources, transform it to appropriate formats, and load it into analytical systems.\",\n    },\n\n    {\n      word: \"distributed computing\",\n      translation: \"informatique distribuée\",\n      example:\n        \"Distributed computing frameworks parallelize data processing across multiple machines.\",\n    },\n\n    {\n      word: \"streaming analytics\",\n      translation: \"analyse en continu\",\n      example:\n        \"Streaming analytics processes data in real-time as it arrives rather than in batches.\",\n    },\n\n    // Applications et considérations éthiques (50 mots)\n\n    {\n      word: \"personalization algorithm\",\n      translation: \"algorithme de personnalisation\",\n      example:\n        \"Personalization algorithms tailor experiences to individual users based on their characteristics and history.\",\n    },\n\n    {\n      word: \"virtual assistant\",\n      translation: \"assistant virtuel\",\n      example:\n        \"The virtual assistant integrates with multiple systems to perform tasks through natural language commands.\",\n    },\n\n    {\n      word: \"fraud detection\",\n      translation: \"détection de fraude\",\n      example:\n        \"Advanced fraud detection systems identify suspicious patterns that indicate potentially illicit activities.\",\n    },\n    {\n      word: \"image recognition\",\n      translation: \"reconnaissance d'image\",\n      example:\n        \"Image recognition technologies automatically identify objects, people, and activities in visual data.\",\n    },\n\n    {\n      word: \"natural language understanding\",\n      translation: \"compréhension du langage naturel\",\n      example:\n        \"Natural language understanding extracts meaning and intent from human communication.\",\n    },\n    {\n      word: \"natural language generation\",\n      translation: \"génération de langage naturel\",\n      example:\n        \"Natural language generation produces human-like text based on provided information and context.\",\n    },\n    {\n      word: \"text summarization\",\n      translation: \"résumé de texte\",\n      example:\n        \"Automatic text summarization condenses documents while preserving key information and meaning.\",\n    },\n    {\n      word: \"machine translation\",\n      translation: \"traduction automatique\",\n      example:\n        \"Neural machine translation systems convert text between languages while maintaining semantic meaning.\",\n    },\n    {\n      word: \"demand forecasting\",\n      translation: \"prévision de la demande\",\n      example:\n        \"Demand forecasting models predict future customer requirements based on historical patterns and contextual factors.\",\n    },\n    {\n      word: \"dynamic pricing\",\n      translation: \"tarification dynamique\",\n      example:\n        \"Dynamic pricing algorithms adjust rates in real-time based on demand, competition, and other market factors.\",\n    },\n\n    {\n      word: \"customer lifetime value prediction\",\n      translation: \"prédiction de la valeur vie client\",\n      example:\n        \"Advanced models forecast customer lifetime value to optimize acquisition and retention strategies.\",\n    },\n    {\n      word: \"churn prediction\",\n      translation: \"prédiction d'attrition\",\n      example:\n        \"Churn prediction identifies customers likely to discontinue services, enabling proactive retention efforts.\",\n    },\n    {\n      word: \"algorithmic trading\",\n      translation: \"trading algorithmique\",\n      example:\n        \"Algorithmic trading systems execute financial transactions based on predefined rules and market conditions.\",\n    },\n    {\n      word: \"risk modeling\",\n      translation: \"modélisation du risque\",\n      example:\n        \"Sophisticated risk modeling evaluates potential threats across multiple variables and scenarios.\",\n    },\n    {\n      word: \"credit scoring\",\n      translation: \"évaluation du crédit\",\n      example:\n        \"Machine learning credit scoring assesses default risk using diverse data beyond traditional financial factors.\",\n    },\n    {\n      word: \"supply chain optimization\",\n      translation: \"optimisation de la chaîne d'approvisionnement\",\n      example:\n        \"AI-driven supply chain optimization balances inventory, transportation, and production constraints for maximum efficiency.\",\n    },\n\n    {\n      word: \"model transparency\",\n      translation: \"transparence du modèle\",\n      example:\n        \"Model transparency enables understanding of how AI systems arrive at specific decisions or predictions.\",\n    },\n    {\n      word: \"black box problem\",\n      translation: \"problème de la boîte noire\",\n      example:\n        \"The black box problem refers to AI systems producing outputs without explainable reasoning processes.\",\n    },\n\n    {\n      word: \"feature importance\",\n      translation: \"importance des caractéristiques\",\n      example:\n        \"Feature importance analysis reveals which variables most significantly influence model predictions.\",\n    },\n    {\n      word: \"model interpretability\",\n      translation: \"interprétabilité du modèle\",\n      example:\n        \"Model interpretability techniques help humans understand how AI systems reach specific conclusions.\",\n    },\n\n    {\n      word: \"demographic parity\",\n      translation: \"parité démographique\",\n      example:\n        \"Demographic parity requires equal prediction rates across protected groups regardless of base rates.\",\n    },\n\n    {\n      word: \"bias mitigation\",\n      translation: \"atténuation des biais\",\n      example:\n        \"Bias mitigation techniques address unfairness in training data and model behavior.\",\n    },\n\n    {\n      word: \"privacy-preserving machine learning\",\n      translation: \"apprentissage automatique respectueux de la vie privée\",\n      example:\n        \"Privacy-preserving machine learning enables analysis without exposing individual sensitive data.\",\n    },\n\n    {\n      word: \"model governance\",\n      translation: \"gouvernance des modèles\",\n      example:\n        \"Model governance establishes policies and procedures for responsible AI development and deployment.\",\n    },\n\n    {\n      word: \"human-AI collaboration\",\n      translation: \"collaboration homme-IA\",\n      example:\n        \"Human-AI collaboration leverages complementary strengths of people and machines for enhanced outcomes.\",\n    },\n\n    {\n      word: \"AI regulation\",\n      translation: \"réglementation de l'IA\",\n      example:\n        \"AI regulation frameworks establish boundaries and requirements for artificial intelligence development and use.\",\n    },\n\n    {\n      word: \"algorithmic impact assessment\",\n      translation: \"évaluation de l'impact algorithmique\",\n      example:\n        \"Algorithmic impact assessments evaluate potential consequences before deploying automated systems.\",\n    },\n  ],\n};\n\n"],"mappings":";;;;AAAO,IAAMA,KAAK,GAAAC,OAAA,CAAAD,KAAA,GAAG;EACnBE,KAAK,EAAE,iDAAiD;EACxDC,KAAK,EAAE,CAGL;IACEC,IAAI,EAAE,iBAAiB;IACvBC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,WAAW;IACjBC,WAAW,EAAE,iBAAiB;IAC9BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,6BAA6B;IACnCC,WAAW,EAAE,kCAAkC;IAC/CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,mBAAmB;IAChCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,sBAAsB;IAC5BC,WAAW,EAAE,sBAAsB;IACnCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,gBAAgB;IACtBC,WAAW,EAAE,gBAAgB;IAC7BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,YAAY;IAClBC,WAAW,EAAE,cAAc;IAC3BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,0BAA0B;IAChCC,WAAW,EAAE,8BAA8B;IAC3CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,iBAAiB;IAC9BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,wBAAwB;IAC9BC,WAAW,EAAE,+BAA+B;IAC5CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,8BAA8B;IACpCC,WAAW,EAAE,4BAA4B;IACzCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,0BAA0B;IAChCC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,cAAc;IAC3BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,gCAAgC;IACtCC,WAAW,EAAE,8BAA8B;IAC3CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,8BAA8B;IACpCC,WAAW,EAAE,wCAAwC;IACrDC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EAGD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,yBAAyB;IACtCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,uBAAuB;IAC7BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,uBAAuB;IAC7BC,WAAW,EAAE,0BAA0B;IACvCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,kBAAkB;IAC/BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,SAAS;IACfC,WAAW,EAAE,SAAS;IACtBC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,gBAAgB;IACtBC,WAAW,EAAE,eAAe;IAC5BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,YAAY;IAClBC,WAAW,EAAE,eAAe;IAC5BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,sBAAsB;IACnCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,uBAAuB;IAC7BC,WAAW,EAAE,0BAA0B;IACvCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,gBAAgB;IACtBC,WAAW,EAAE,gBAAgB;IAC7BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,sBAAsB;IAC5BC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,8BAA8B;IACpCC,WAAW,EAAE,gCAAgC;IAC7CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,wBAAwB;IAC9BC,WAAW,EAAE,iCAAiC;IAC9CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,sBAAsB;IAC5BC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,4BAA4B;IAClCC,WAAW,EAAE,4BAA4B;IACzCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,eAAe;IAC5BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,yBAAyB;IAC/BC,WAAW,EAAE,4BAA4B;IACzCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,gBAAgB;IAC7BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,oBAAoB;IACjCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,0BAA0B;IACvCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,8BAA8B;IAC3CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,0BAA0B;IACvCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,sBAAsB;IAC5BC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,wBAAwB;IAC9BC,WAAW,EAAE,+BAA+B;IAC5CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,SAAS;IACfC,WAAW,EAAE,SAAS;IACtBC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,mBAAmB;IAChCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EAID;IACEF,IAAI,EAAE,2BAA2B;IACjCC,WAAW,EAAE,kCAAkC;IAC/CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,SAAS;IACfC,WAAW,EAAE,UAAU;IACvBC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,aAAa;IAC1BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,qBAAqB;IAClCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,8BAA8B;IACpCC,WAAW,EAAE,oCAAoC;IACjDC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,cAAc;IAC3BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,2BAA2B;IACjCC,WAAW,EAAE,wCAAwC;IACrDC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,0BAA0B;IACvCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,SAAS;IACfC,WAAW,EAAE,iBAAiB;IAC9BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,cAAc;IACpBC,WAAW,EAAE,iBAAiB;IAC9BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,WAAW;IACjBC,WAAW,EAAE,aAAa;IAC1BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,UAAU;IAChBC,WAAW,EAAE,oBAAoB;IACjCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,2BAA2B;IACxCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,gCAAgC;IAC7CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,aAAa;IACnBC,WAAW,EAAE,eAAe;IAC5BC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,uBAAuB;IAC7BC,WAAW,EAAE,yBAAyB;IACtCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,oBAAoB;IACjCC,OAAO,EACL;EACJ,CAAC,EAID;IACEF,IAAI,EAAE,2BAA2B;IACjCC,WAAW,EAAE,gCAAgC;IAC7CC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,mBAAmB;IAChCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,iBAAiB;IACvBC,WAAW,EAAE,qBAAqB;IAClCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,gCAAgC;IACtCC,WAAW,EAAE,kCAAkC;IAC/CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,6BAA6B;IACnCC,WAAW,EAAE,+BAA+B;IAC5CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,iBAAiB;IAC9BC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,yBAAyB;IACtCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,iBAAiB;IACvBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oCAAoC;IAC1CC,WAAW,EAAE,oCAAoC;IACjDC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,qBAAqB;IAC3BC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,gBAAgB;IACtBC,WAAW,EAAE,sBAAsB;IACnCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,2BAA2B;IACjCC,WAAW,EAAE,+CAA+C;IAC5DC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,mBAAmB;IACzBC,WAAW,EAAE,4BAA4B;IACzCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,iCAAiC;IAC9CC,OAAO,EACL;EACJ,CAAC,EACD;IACEF,IAAI,EAAE,wBAAwB;IAC9BC,WAAW,EAAE,4BAA4B;IACzCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,oBAAoB;IAC1BC,WAAW,EAAE,sBAAsB;IACnCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,iBAAiB;IACvBC,WAAW,EAAE,uBAAuB;IACpCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,qCAAqC;IAC3CC,WAAW,EAAE,wDAAwD;IACrEC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,kBAAkB;IACxBC,WAAW,EAAE,yBAAyB;IACtCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,wBAAwB;IAC9BC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,eAAe;IACrBC,WAAW,EAAE,wBAAwB;IACrCC,OAAO,EACL;EACJ,CAAC,EAED;IACEF,IAAI,EAAE,+BAA+B;IACrCC,WAAW,EAAE,sCAAsC;IACnDC,OAAO,EACL;EACJ,CAAC;AAEL,CAAC","ignoreList":[]}